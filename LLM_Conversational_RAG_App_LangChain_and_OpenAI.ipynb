{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nazifmhd/LLM-Conversational-RAG-App-LangChain-and-OpenAI/blob/main/LLM_Conversational_RAG_App_LangChain_and_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conversational Rag Application With LangChain And OpenAI LLM**"
      ],
      "metadata": {
        "id": "O23IIizyJXxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC32K3MeJqr4",
        "outputId": "ed8ed4bd-d6d0-4299-ad65-6c327958d87a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary packages\n",
        "!pip install langchain -qU\n",
        "!pip install langchain-openai -qU\n",
        "!pip install langchain-chroma -qU\n",
        "!pip install langchain-community -qU"
      ],
      "metadata": {
        "id": "DrkriQqnQnNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4217ad2-18b9-4d4f-d094-55c7efff8ea5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "DoEtw7fFRQyS"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialize OpenAI LLM**"
      ],
      "metadata": {
        "id": "nIaJxi5fRWy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# set OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    temperature = 0\n",
        ")"
      ],
      "metadata": {
        "id": "t6Tz07-KRVjM"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initialize Embedding Model**"
      ],
      "metadata": {
        "id": "m_0fFopasmME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\"\n",
        ")"
      ],
      "metadata": {
        "id": "JliGaBiosei5"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load PDF Document**"
      ],
      "metadata": {
        "id": "wEGqzO3Us61H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf -qU"
      ],
      "metadata": {
        "id": "HFK2_NxatWYl"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# load the pdf document\n",
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf\")\n",
        "\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "A7teXXAys6JN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)  # page count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aza9bt-ttQj-",
        "outputId": "56446b1b-3fb6-41fa-99b0-cfdd63fb2dc2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtTN9gUEtauc",
        "outputId": "b534eda7-5799-49a8-974c-3b15e943abf7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 0, 'page_label': ''}, page_content='Mohamed Nazif\\nMachine Learning Engineer | Data Scientist | AI Engineer\\nColombo, Sri Lanka • mohamednazif2001@gmail.com • +94778521218\\nMy Portfolio • linkedin.com/in/nazifmhd • github.com/nazifmhd\\nPersonal Summary\\nMotivated and responsible professional with a solid foundation in Machine Learning Engineering, Data Science,\\nand Artificial Intelligence. Passionate about advancing my skills and knowledge in the tech industry , with a focus\\non developing innovative, data-driven, and AI-powered solutions. Currently seeking opportunities to apply my\\nexpertise in machine learning, artificial intelligence, data analysis, and predictive modeling while continuing to\\ngrow and contribute to impactful projects.\\nExperience\\nAI Agent Intern AbsolX, Kandy, Sri Lanka\\nFebruary 20, 2025 – Present\\n• Involved in the design and development of AI Agents capable of autonomous decision-making and goal-oriented\\nbehavior.\\n• Worked on integrating LLM-based AI agents with various APIs and tools for real-world task automation.\\n• Conducted prompt engineering and fine-tuning of large language models (LLMs) to enhance agent performance.\\n• Collaborated with a team to implement memory modules and planning strategies for multi-step task execution.\\n• Participated in testing and deploying agents in simulated and production environments, ensuring robust and\\nscalable behavior.\\nTechnical Expertise\\n• Programming Languages: Python, R, SQL, C++\\n• Artificial Intelligence & Machine Learning:\\n– AI Techniques: Reinforcement Learning, Knowledge Representation, Expert Systems\\n– ML Techniques: Supervised & Unsupervised Learning, Regression, Classification, Clustering\\n– Deep Learning: Neural Networks, CNNs, RNNs, Transfer Learning, GANs\\n• Generative AI:\\n– Techniques: Text Generation, Image Synthesis, Code Generation, Style Transfer\\n• ML Frameworks & Libraries: TensorFlow, PyTorch, Keras, Scikit-learn, Pandas, NumPy\\n• Natural Language Processing:\\n– Text Preprocessing, Sentiment Analysis\\n– Tools: NLTK, spaCy , Hugging Face Transformers, GPT-based models\\n• Computer Vision: OpenCV, YOLO, Object Detection, Face Recognition\\n• Databases:\\n– Relational: MySQL, PostgreSQL\\n– NoSQL: MongoDB\\n• Cloud & DevOps: AWS, GCP, Azure, Docker, Kubernetes\\n• Development Tools:\\n– Version Control: Git, GitHub, GitLab\\n– IDEs & Notebooks: Jupyter Notebooks, Google Colab, Anaconda\\n– API Development: RESTful APIs, Flask, Django\\n• Data Analysis & Visualization:\\n– Data Cleaning, Exploratory Data Analysis (EDA)')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQDB7qZHtmln",
        "outputId": "28fd50de-0bda-497e-c819-b813b4ce29ed"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'producer': 'pdfTeX-1.40.26',\n",
              " 'creator': 'LaTeX',\n",
              " 'creationdate': '2025-04-21T09:14:41+00:00',\n",
              " 'author': 'Mohamed Nazif',\n",
              " 'keywords': '',\n",
              " 'moddate': '2025-04-21T09:14:41+00:00',\n",
              " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0',\n",
              " 'subject': '',\n",
              " 'title': \"Mohamed Nazif's CV\",\n",
              " 'trapped': '/False',\n",
              " 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf',\n",
              " 'total_pages': 3,\n",
              " 'page': 0,\n",
              " 'page_label': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "HETvq6ZNtudo",
        "outputId": "0846c8c8-25cd-4108-ceab-e2c047a782ed"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mohamed Nazif\\nMachine Learning Engineer | Data Scientist | AI Engineer\\nColombo, Sri Lanka • mohamednazif2001@gmail.com • +94778521218\\nMy Portfolio • linkedin.com/in/nazifmhd • github.com/nazifmhd\\nPersonal Summary\\nMotivated and responsible professional with a solid foundation in Machine Learning Engineering, Data Science,\\nand Artificial Intelligence. Passionate about advancing my skills and knowledge in the tech industry , with a focus\\non developing innovative, data-driven, and AI-powered solutions. Currently seeking opportunities to apply my\\nexpertise in machine learning, artificial intelligence, data analysis, and predictive modeling while continuing to\\ngrow and contribute to impactful projects.\\nExperience\\nAI Agent Intern AbsolX, Kandy, Sri Lanka\\nFebruary 20, 2025 – Present\\n• Involved in the design and development of AI Agents capable of autonomous decision-making and goal-oriented\\nbehavior.\\n• Worked on integrating LLM-based AI agents with various APIs and tools for real-world task automation.\\n• Conducted prompt engineering and fine-tuning of large language models (LLMs) to enhance agent performance.\\n• Collaborated with a team to implement memory modules and planning strategies for multi-step task execution.\\n• Participated in testing and deploying agents in simulated and production environments, ensuring robust and\\nscalable behavior.\\nTechnical Expertise\\n• Programming Languages: Python, R, SQL, C++\\n• Artificial Intelligence & Machine Learning:\\n– AI Techniques: Reinforcement Learning, Knowledge Representation, Expert Systems\\n– ML Techniques: Supervised & Unsupervised Learning, Regression, Classification, Clustering\\n– Deep Learning: Neural Networks, CNNs, RNNs, Transfer Learning, GANs\\n• Generative AI:\\n– Techniques: Text Generation, Image Synthesis, Code Generation, Style Transfer\\n• ML Frameworks & Libraries: TensorFlow, PyTorch, Keras, Scikit-learn, Pandas, NumPy\\n• Natural Language Processing:\\n– Text Preprocessing, Sentiment Analysis\\n– Tools: NLTK, spaCy , Hugging Face Transformers, GPT-based models\\n• Computer Vision: OpenCV, YOLO, Object Detection, Face Recognition\\n• Databases:\\n– Relational: MySQL, PostgreSQL\\n– NoSQL: MongoDB\\n• Cloud & DevOps: AWS, GCP, Azure, Docker, Kubernetes\\n• Development Tools:\\n– Version Control: Git, GitHub, GitLab\\n– IDEs & Notebooks: Jupyter Notebooks, Google Colab, Anaconda\\n– API Development: RESTful APIs, Flask, Django\\n• Data Analysis & Visualization:\\n– Data Cleaning, Exploratory Data Analysis (EDA)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Split Documents Into Chunks**"
      ],
      "metadata": {
        "id": "2EECpXL3tevT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# initialize the text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 400,\n",
        "    chunk_overlap = 50,\n",
        ")\n",
        "\n",
        "# split the document into chunks\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "y3A4t92jtbx6"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Nn_qA8JuR3S",
        "outputId": "874134c6-9d0b-4db3-a065-972b33656279"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmeYZoOOulpd",
        "outputId": "cc01e5ca-0216-4310-9661-2ea14a845819"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 0, 'page_label': ''}, page_content='Mohamed Nazif\\nMachine Learning Engineer | Data Scientist | AI Engineer\\nColombo, Sri Lanka • mohamednazif2001@gmail.com • +94778521218\\nMy Portfolio • linkedin.com/in/nazifmhd • github.com/nazifmhd\\nPersonal Summary\\nMotivated and responsible professional with a solid foundation in Machine Learning Engineering, Data Science,'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 0, 'page_label': ''}, page_content='and Artificial Intelligence. Passionate about advancing my skills and knowledge in the tech industry , with a focus\\non developing innovative, data-driven, and AI-powered solutions. Currently seeking opportunities to apply my\\nexpertise in machine learning, artificial intelligence, data analysis, and predictive modeling while continuing to\\ngrow and contribute to impactful projects.\\nExperience'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 0, 'page_label': ''}, page_content='Experience\\nAI Agent Intern AbsolX, Kandy, Sri Lanka\\nFebruary 20, 2025 – Present\\n• Involved in the design and development of AI Agents capable of autonomous decision-making and goal-oriented\\nbehavior.\\n• Worked on integrating LLM-based AI agents with various APIs and tools for real-world task automation.'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 0, 'page_label': ''}, page_content='• Conducted prompt engineering and fine-tuning of large language models (LLMs) to enhance agent performance.\\n• Collaborated with a team to implement memory modules and planning strategies for multi-step task execution.\\n• Participated in testing and deploying agents in simulated and production environments, ensuring robust and\\nscalable behavior.\\nTechnical Expertise'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 0, 'page_label': ''}, page_content='scalable behavior.\\nTechnical Expertise\\n• Programming Languages: Python, R, SQL, C++\\n• Artificial Intelligence & Machine Learning:\\n– AI Techniques: Reinforcement Learning, Knowledge Representation, Expert Systems\\n– ML Techniques: Supervised & Unsupervised Learning, Regression, Classification, Clustering\\n– Deep Learning: Neural Networks, CNNs, RNNs, Transfer Learning, GANs\\n• Generative AI:'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 0, 'page_label': ''}, page_content='• Generative AI:\\n– Techniques: Text Generation, Image Synthesis, Code Generation, Style Transfer\\n• ML Frameworks & Libraries: TensorFlow, PyTorch, Keras, Scikit-learn, Pandas, NumPy\\n• Natural Language Processing:\\n– Text Preprocessing, Sentiment Analysis\\n– Tools: NLTK, spaCy , Hugging Face Transformers, GPT-based models\\n• Computer Vision: OpenCV, YOLO, Object Detection, Face Recognition'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 0, 'page_label': ''}, page_content='• Databases:\\n– Relational: MySQL, PostgreSQL\\n– NoSQL: MongoDB\\n• Cloud & DevOps: AWS, GCP, Azure, Docker, Kubernetes\\n• Development Tools:\\n– Version Control: Git, GitHub, GitLab\\n– IDEs & Notebooks: Jupyter Notebooks, Google Colab, Anaconda\\n– API Development: RESTful APIs, Flask, Django\\n• Data Analysis & Visualization:\\n– Data Cleaning, Exploratory Data Analysis (EDA)'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 1, 'page_label': ''}, page_content='– Visualization Tools: Matplotlib, Seaborn, Tableau, Power BI\\n• Advanced Techniques:\\n– Time Series Analysis\\n– Recommendation Systems\\n– A/B Testing\\n– Optimization: Gradient Descent, Hyperparameter Tuning\\n• AI Ethics & Best Practices:\\n– Bias Detection & Mitigation\\n– AI Model Interpretability\\nEducation\\n• University of Moratuwa, Bachelor’s of Information Technology (June 2022 – Present)'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 1, 'page_label': ''}, page_content='• Institute of Technology, University of Moratuwa, NDT in Information Technology (Dec 2022 – Present)\\n• AL-Hira Maha Vidyalaya, Physical Science Stream (2018 – 2020)\\nCertifications\\n• Machine Learning Specialization - DeepLearning.AI\\n• Data Science with Python - University of Colombo\\n• PyData Workshop Series (Python & Data Science) - PyData NYC\\n• Postman Student Expert\\nProjects'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 1, 'page_label': ''}, page_content='• Postman Student Expert\\nProjects\\nVisioSense - Smart Assistive Technology for the Visually Impaired (Team Lead)\\n• Engineered an innovative assistive technology solution that improved object detection accuracy by 85% for\\nvisually impaired users through smart sunglasses integration\\n• Implemented real-time video processing using ESP32-CAM, achieving 30 FPS streaming and <200ms latency in'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 1, 'page_label': ''}, page_content='object detection\\n• Developed and trained custom YOLOv8 model to recognize 50+ common objects with 92% accuracy\\n• Reduced emergency response time by 70% through implementation of one-touch GPS-enabled alert system\\n• Architected cross-platform mobile application serving 100+ daily active users on both iOS & Android\\nTechnical Implementation:'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 1, 'page_label': ''}, page_content='Technical Implementation:\\n– IoT: Programmed ESP32-CAM microcontroller using C++ and Arduino IDE for efficient video capture\\n– Machine Learning: Trained YOLOv8 model on custom dataset of 10,000+ images\\n– Mobile Development: Built Flutter/Dart application with user satisfaction interfaces\\n– Backend: Implemented Firebase real-time database with 99.9% uptime'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 1, 'page_label': ''}, page_content='– Security: Integrated Gmail SMTP for secure OTP verification and user authentication\\n– Communication: Established MQTT protocol for reliable real-time data transmission\\nArtificial Intelligence & Deep Learning\\n• Real-Time Stress Tracking & Productivity Monitoring System\\nDesigned and implemented an AI-powered stress monitoring and productivity tracking system using FastAPI,'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 1, 'page_label': ''}, page_content='MongoDB, and WebSockets for real-time data updates. Developed a deep learning model (LSTM) for stress\\nlevel prediction based on user activity (e.g., typing speed, focus levels). Integrated a web dashboard (React +\\nVite + Tailwind CSS) with real-time alerts and historical stress analytics using Chart.js. The system supports:\\n– Real-time stress prediction using an LSTM model.'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 1, 'page_label': ''}, page_content='– WebSocket-based distraction alerts and AI-driven productivity insights.\\n– Historical stress analysis via MongoDB, visualized on an interactive dashboard.\\n– Future Work: Implementing user authentication and personalized recommendations.\\n• Chicken Disease Classification'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 2, 'page_label': ''}, page_content='Developed a CNN model to classify chicken diseases from feces images, managing workflow setup, pipeline\\ncreation, and version control with DVC. Automated deployment on AWS via CI/CD with GitHub Actions,\\nbuilding Docker images for EC2 deployment. Streamlined poultry disease detection with continuous model\\nupdates on the cloud.\\n• Text Summarizer with AWS'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 2, 'page_label': ''}, page_content='updates on the cloud.\\n• Text Summarizer with AWS\\nDeveloped a text summarization pipeline using NLP techniques. The project included configuration\\nmanagement, pipeline creation, and deployment automation via CI/CD using GitHub Actions. Dockerized the\\napplication and deployed it on AWS EC2 with seamless integration of ECR for container management.'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 2, 'page_label': ''}, page_content='• LLM Agents Using LangChain and OpenAI (Generative AI)\\n• LLM Conversational RAG Application (Generative AI)\\n• LSTM Sentiment Analysis IMDB Reviews\\n• Customer Churn Prediction\\n• Image Classification MobileNetV2\\n• Breast Cancer Classification with Neural Network\\n• Brain Tumor Segmentation\\n• Virtual Painter\\nFoodie - Restaurant Management System'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 2, 'page_label': ''}, page_content='Foodie - Restaurant Management System\\n• Developed and launched restaurant management platform\\n• Increased order processing efficiency by 75% through automated order management\\n• Implemented secure payment gateway processing 500+ daily transactions\\n• Reduced customer wait time by 40% through streamlined ordering process\\nTechnical Stack:\\n– Backend: PHP/CodeIgniter with RESTful API architecture'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 2, 'page_label': ''}, page_content='– Database: MySQL optimization handling 10,000+ daily queries\\n– Frontend: Responsive design using Bootstrap with 98% mobile compatibility\\nConsole Applications\\n• Python Billing System (Team Lead)\\n• Java Library Management System\\nExtracurricular Activities\\n• University Colors for Volleyball - University Games 2024\\n• Volleyball - Qualified for Provincial Level (School Level, 2019)'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 2, 'page_label': ''}, page_content='• Chess - Qualified for Provincial Level (School Level, 2016, 2017, 2018, 2019)\\n• Player - Volleyball Team, University of Moratuwa\\n• Coordinator - Volleyball & Chess, Sports Club of ITUM (Present)\\nReferences\\n• Mrs.A.U.P. Athukorala\\nMPhil (reading), PGD in Computer Science, BSc\\nEngineering\\nLecturer (Probationary)\\nDivision of Information Technology\\nInstitute of Technology , University of Moratuwa'),\n",
              " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX', 'creationdate': '2025-04-21T09:14:41+00:00', 'author': 'Mohamed Nazif', 'keywords': '', 'moddate': '2025-04-21T09:14:41+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) kpathsea version 6.4.0', 'subject': '', 'title': \"Mohamed Nazif's CV\", 'trapped': '/False', 'source': '/content/drive/MyDrive/Mohamed Nazif_Resume (1).pdf', 'total_pages': 3, 'page': 2, 'page_label': ''}, page_content='Institute of Technology , University of Moratuwa\\nEmail: uthpalap@itum.mrt.ac.lk\\nPhone: 011-212 4000 Ext: 1153\\n• Ms. M.S Madhubhashini\\nLecturer\\nDivision of Information Technology\\nInstitute of Technology , University of Moratuwa\\nEmail: sitharam@itum.mrt.ac.lk\\nPhone: +94717055905')]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create Vector Store And Retriever**"
      ],
      "metadata": {
        "id": "TiuFVb8bubOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "# create vector store from the document chunks\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents = splits,\n",
        "    embedding = embedding_model\n",
        ")"
      ],
      "metadata": {
        "id": "b4GcOhn0uZGC"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a retriever from the vector store\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "NU1kpK1U09Jb"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define Prompt Template**"
      ],
      "metadata": {
        "id": "0znR54Pt1HEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# define the system prompt\n",
        "system_prompt = (\n",
        "    \"You are an itelligent chatbot. Use the following context to answer the question.If you don't know the answer, just say that you don't know.\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "# create the prompt template\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        (\"user\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "WAx4t4ZO1GRz"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3eKhPa53aLd",
        "outputId": "b43a8417-cc21-430d-e279-89e8bc902b9c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an itelligent chatbot. Use the following context to answer the question.If you don't know the answer, just say that you don't know.\\n\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create RAG Chain**"
      ],
      "metadata": {
        "id": "Ntceyb2d3kZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "# create the question answering chain\n",
        "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# create the RAG chain\n",
        "rag_chain = create_retrieval_chain(retriever, qa_chain)"
      ],
      "metadata": {
        "id": "f-A3tz753gnw"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Invoke RAG Chain With Example Question**"
      ],
      "metadata": {
        "id": "g-S-0UVW4dVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"Who is Nazif?\"})\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "l6bITB6t4hcB",
        "outputId": "22103678-f825-420b-913c-08d8e638f5b3"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nazif is a Machine Learning Engineer, Data Scientist, and AI Engineer based in Colombo, Sri Lanka. He has a solid foundation in Machine Learning Engineering and Data Science. He has developed and launched a restaurant management platform called Foodie, where he increased order processing efficiency, implemented secure payment gateway processing, and reduced customer wait time. His technical stack includes PHP/CodeIgniter with RESTful API architecture.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"What is RAG Architecture\"})\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "NX8Fevp94x4H",
        "outputId": "2ce0de41-389c-4515-e527-a4003c9c26e5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RAG (Retrieval-Augmented Generation) architecture is a framework that combines retrieval-based and generative AI models to improve the quality of generated text. In RAG, a retriever model first selects relevant information from a large dataset, and then a generative model uses this information to generate coherent and contextually relevant responses. This architecture is commonly used in conversational AI applications to enhance the quality and relevance of generated responses.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"What are the skills Nazif have?\"})\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HO725xuQCBNy",
        "outputId": "e7a148fd-15d9-464c-a2b5-c12d0c54e6fc"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mohamed Nazif has skills in Machine Learning Engineering, Data Science, and AI Engineering.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain.invoke({\"input\": \"Do you remember chat history\"})\n",
        "\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "puqcKTeGCBBl",
        "outputId": "4fec2414-9413-407b-fc96-bc3ab95d676d"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't have the ability to remember chat history. Each conversation is independent and not stored for future reference.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Add Chat History**"
      ],
      "metadata": {
        "id": "FuZ_gT-B6amL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "# define the contextualize system prompt\n",
        "contextualize_system_prompt = (\n",
        "    \"Using chat history and the latest user question, just reformulate question if needed and otherwise return it as is\"\n",
        ")\n",
        "\n",
        "# create the cotextualize prompt template\n",
        "cotextualize_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", contextualize_system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# create the history aware retriever\n",
        "history_aware_retriever = create_history_aware_retriever(llm, retriever, cotextualize_prompt)"
      ],
      "metadata": {
        "id": "OMXfxTs05hhS"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create History Aware Retriever**"
      ],
      "metadata": {
        "id": "8Oiz0MTC6hog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "system_prompt = (\n",
        "    \"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know\"\n",
        "    \"\\n\\n\"\n",
        "    \"{context}\"\n",
        ")\n",
        "\n",
        "# create the prompt template\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "4fU4u0G98HEG"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd-vxl3A9M7y",
        "outputId": "aaf5895a-5378-4a4c-9ce1-dec2ea39d77e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7a76d80fade0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an intelligent chatbot. Use the following context to answer the question. If you don't know the answer, just say that you don't know\\n\\n{context}\"), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the question answering chain\n",
        "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# create the RAG chain\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, qa_chain)"
      ],
      "metadata": {
        "id": "qTetYgMF9Olc"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Manage Chat Sessin History**"
      ],
      "metadata": {
        "id": "KXOswGRx9dw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "# initialize the store for session histories\n",
        "store = {}\n",
        "\n",
        "# function to get the session history for a given session ID\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "# create the conversational RAG chain with session history\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key = \"input\",\n",
        "    history_messages_key = \"chat_history\",\n",
        "    output_messages_key = \"answer\",\n",
        ")"
      ],
      "metadata": {
        "id": "talg9qYB9c6J"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Invoke Conversational RAG Chain With Example Questions**"
      ],
      "metadata": {
        "id": "TkRFmboh_FmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = conversational_rag_chain.invoke(\n",
        "    {\"input\": \"Who is Nazif?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
        ")\n",
        "\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "h8zDXgju_E-I",
        "outputId": "64178053-a91b-4f04-992c-b8c22b9aed21"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nazif is a Machine Learning Engineer, Data Scientist, and AI Engineer based in Colombo, Sri Lanka. He has a solid foundation in Machine Learning Engineering and Data Science. He has developed and launched a restaurant management platform called \"Foodie\" which increased order processing efficiency, implemented secure payment gateway processing, and reduced customer wait time. His technical stack includes PHP/CodeIgniter with RESTful API architecture.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = conversational_rag_chain.invoke(\n",
        "    {\"input\": \"What are the skills Nazif have?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
        ")\n",
        "\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "gct38rjY_ii9",
        "outputId": "e43e4fef-dfe0-4014-8a5e-a415e4b0b2da"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nazif has skills in Machine Learning Engineering, Data Science, and AI. Some of his specific skills include:\\n1. Machine Learning\\n2. Data Science\\n3. Python programming\\n4. Deep Learning\\n5. Natural Language Processing\\n6. Computer Vision\\n7. Statistical Analysis\\n8. Data Visualization\\n9. RESTful API architecture\\n10. PHP/CodeIgniter\\n\\nThese skills enable him to work on various projects and contribute effectively to the field of artificial intelligence and data science.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = conversational_rag_chain.invoke(\n",
        "    {\"input\": \"Can you listdown\"},\n",
        "    config={\"configurable\": {\"session_id\": \"101\"}},\n",
        ")\n",
        "\n",
        "response[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "f7XGeefyBfbH",
        "outputId": "56e741f8-b9d1-4084-c570-3bd531580055"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, but I don't have the specific list of skills that Nazif possesses. However, based on the context provided, I can mention some general skills that are commonly associated with Machine Learning Engineers, Data Scientists, and AI Engineers. If you have any specific questions or need more information, feel free to ask!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    }
  ]
}